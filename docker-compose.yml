version: "3.6"

services:
  auto-nlp-core:
    container_name: ${COMPOSE_PROJECT_NAME}-core
    image: ghcr.io/fhswf/auto-nlp-core
    build:
      context: .
      target: core
      args:
        - ASSET_PATH=${ASSET_PATH}
        - GRAPHQL_URL=${GRAPHQL_URL}
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      - auto-nlp-huggingface-search
    networks:
      - auto-nlp-services
    expose:
      - ${AUTONLP_CORE_PORT:-3000}
    environment:
      - MONGODB_URI=mongodb://${COMPOSE_PROJECT_NAME}-mongodb:27017
      - MONGODB_USER=${MONGODB_USER}
      - MONGODB_PASSWORD=${MONGODB_PASSWORD}
      - AUTONLP_CORE_PORT=${AUTONLP_CORE_PORT:-3000}
      - AUTONLP_HF_SEARCH_SERVICE_URL=http://${COMPOSE_PROJECT_NAME}-huggingface-search:${AUTONLP_HFSEARCH_PORT:-3001}
      - AUTONLP_DEPLOYMENT_URL=http://${COMPOSE_PROJECT_NAME}-deployment:${AUTONLP_DEPLOYMENT_PORT:-3002}
      - AUTONLP_CORE_PUBLIC_URL=${AUTONLP_CORE_PUBLIC_URL}
      - AUTONLP_DEPLOYMENT_PROXY_ENTRYPOINT_URL=${AUTONLP_DEPLOYMENT_PROXY_ENTRYPOINT_URL}
#      - AUTONLP_DEPLOYMENT_URL=http://auto-nlp-deployment-${ENVIRONMENT:-prod}:${AUTONLP_DEPLOYMENT_PORT:-3002}
#      - GITHUB_TOKEN=${GITHUB_TOKEN}
#      - NODE_ENV=${AUTONLP_ENV}
    labels:
      - traefik.enable=true
      - traefik.http.routers.${COMPOSE_PROJECT_NAME}-core.rule=PathPrefix(`/${ENVIRONMENT}/core`)
      - traefik.http.routers.${COMPOSE_PROJECT_NAME}-core.middlewares=${COMPOSE_PROJECT_NAME}-core@docker
      - traefik.http.middlewares.${COMPOSE_PROJECT_NAME}-core.stripprefix.prefixes=/${ENVIRONMENT}/core
    restart: always

  auto-nlp-nginx:
    container_name: ${COMPOSE_PROJECT_NAME}-nginx
    image: ghcr.io/fhswf/auto-nlp-nginx
    build:
      context: .
      target: nginx
      args:
        - ASSET_PATH=${ASSET_PATH}
        - GRAPHQL_URL=${GRAPHQL_URL}
    expose:
      - 80
    networks:
      - auto-nlp-services
    labels:
      - traefik.enable=true
      - traefik.http.routers.${COMPOSE_PROJECT_NAME}-nginx.rule=PathPrefix(`/${ENVIRONMENT}/static`)
      - traefik.http.routers.${COMPOSE_PROJECT_NAME}-nginx.middlewares=${COMPOSE_PROJECT_NAME}-nginx@docker
      - traefik.http.middlewares.${COMPOSE_PROJECT_NAME}-nginx.stripprefix.prefixes=/${ENVIRONMENT}/static

  auto-nlp-huggingface-search:
    container_name: ${COMPOSE_PROJECT_NAME}-huggingface-search
    image: ghcr.io/fhswf/auto-nlp-huggingface-search
    build:
      context: packages/auto-nlp-huggingface-search
      args:
        PORT: ${AUTONLP_HFSEARCH_PORT:-3001}
    expose:
      - "${AUTONLP_HFSEARCH_PORT:-3001}"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - auto-nlp-services
    environment:
      - PYTHON_ENV=${AUTONLP_ENV}
    labels:
      - traefik.enable=true
      - traefik.http.routers.${COMPOSE_PROJECT_NAME}-mlflow.rule=PathPrefix(`/${ENVIRONMENT}/mlflow`)
      - traefik.http.routers.${COMPOSE_PROJECT_NAME}-mlflow.middlewares=${COMPOSE_PROJECT_NAME}-core@docker
      - traefik.http.middlewares.${COMPOSE_PROJECT_NAME}-mlflow.stripprefix.prefixes=/${ENVIRONMENT}/mlflow
    restart: always

  auto-nlp-deployment:
    container_name: ${COMPOSE_PROJECT_NAME}-deployment
    image: ghcr.io/fhswf/auto-nlp-deployment
    build:
      context: packages/auto-nlp-deployment
      args:
        PORT: ${AUTONLP_DEPLOYMENT_PORT:-3002}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 3
              capabilities: [gpu]
    expose:
      - "${AUTONLP_DEPLOYMENT_PORT:-3002}"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - auto-nlp-services
    environment:
      - DOCKER_PASSWORD=${GITHUB_TOKEN}
      - GITHUB_TOKEN=${GITHUB_TOKEN}
      - REDIS_HOST=${REDIS_HOST:-auto-nlp-redis}
      - REDIS_PORT=${REDIS_PORT:-6379}
#      - REDIS_USER=${REDIS_USER}
#      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - MLFLOW_TRACKING_URI=${MLFLOW_TRACKING_URI}
      - MLFLOW_TRACKING_USERNAME=${MLFLOW_TRACKING_USERNAME}
      - MLFLOW_TRACKING_PASSWORD=${MLFLOW_TRACKING_PASSWORD}
      - MLFLOW_S3_ENDPOINT_URL=${MLFLOW_S3_ENDPOINT_URL:-http://auto-nlp-minio:9000}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - PYTHON_ENV=${AUTONLP_ENV}
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /home/autonlp/.ssh:/root/.ssh:ro
    restart: always

  auto-nlp-deployment-executor:
    container_name: ${COMPOSE_PROJECT_NAME}-deployment-executor
    image: ghcr.io/fhswf/auto-nlp-deployment
    entrypoint: pipenv run dramatiq --processes ${DRAMATIQ_PROCS:-10} --path="./src" main_dramatiq
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 3
              capabilities: [gpu]

    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - auto-nlp-services
    environment:
      - GITHUB_TOKEN=${GITHUB_TOKEN}
      - REDIS_HOST=${REDIS_HOST:-auto-nlp-redis}
      - REDIS_PORT=${REDIS_PORT:-6379}
#      - REDIS_USER=${REDIS_USER}
#      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - PYTHON_ENV=${AUTONLP_ENV}
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /home/autonlp/.ssh:/root/.ssh:ro
#      - $SSH_AUTH_SOCK:/var/run/ssh-agent # Forward local machine SSH agent to docker
    restart: always

  auto-nlp-traefik:
    image: "traefik:latest"
    container_name: ${COMPOSE_PROJECT_NAME}-traefik
    command:
      - "--api.insecure=true"
      - "--providers.docker=true"
      - "--providers.docker.exposedbydefault=false"
      - "--providers.http=true"
      - "--providers.http.endpoint=http://auto-nlp-core-${ENVIRONMENT}:${AUTONLP_CORE_PORT:-3000}/deployments/proxy/config"
      - "--entrypoints.web.address=:80"
      - "--pilot.token=${PILOT_TOKEN}"
      - "--accesslog=true"
      - "--accesslog.filepath=/var/logs/traefik"
      - "--log.level=DEBUG"
      - "--log.filePath=/var/logs/traefik.log"
    ports:
      - "${AUTONLP_TRAEFIK_ENTRYPOINT_PORT}:80"
      - "${AUTONLP_TRAEFIK_ADMIN_PORT}:8080"
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock:ro"
      - "/home/autonlp/logs:/var/logs:rw"
    networks:
      - auto-nlp-deployments
      - auto-nlp-services
    restart: always

  auto-nlp-redis:
    image: "redis:latest"
    container_name: ${COMPOSE_PROJECT_NAME}-redis
    expose:
      - "6379"
    networks:
      - auto-nlp-services
    restart: always

  auto-nlp-mongodb:
    image: "mongo:latest"
    container_name: ${COMPOSE_PROJECT_NAME}-mongodb
    volumes:
      - "/home/autonlp/mongodb/${COMPOSE_PROJECT_NAME}:/data/db"
    environment:
      - MONGO_INITDB_ROOT_USERNAME=${MONGODB_USER}
      - MONGO_INITDB_ROOT_PASSWORD=${MONGODB_PASSWORD}
    expose:
      - "27017"
    networks:
      - auto-nlp-services
    restart: always

  auto-nlp-mlflow:
    image: "ghcr.io/fhswf/mlflow-tracking-server:latest"
    container_name: ${COMPOSE_PROJECT_NAME}-mlflow
    volumes:
      - "/home/autonlp/mlflow:/data"
    expose:
      - 5000
    environment:
      - BACKEND_STORE_URI=${BACKEND_STORE_URI:-sqlite:///data/sqlite.db}
      - BUCKET_URI_OR_LOCAL_PATH=${BUCKET_URI_OR_LOCAL_PATH:-/data/mlruns}
      - MLFLOW_S3_ENDPOINT_URL=${COMPOSE_PROJECT_NAME}-minio:9000
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
    networks:
      - auto-nlp-services
    labels:
      - traefik.enable=true
      - traefik.http.routers.${COMPOSE_PROJECT_NAME}-mlflow.rule=PathPrefix(`/${ENVIRONMENT}/mlflow`)
      - traefik.http.routers.${COMPOSE_PROJECT_NAME}-mlflow.middlewares=${COMPOSE_PROJECT_NAME}-core@docker
      - traefik.http.middlewares.${COMPOSE_PROJECT_NAME}-mlflow.stripprefix.prefixes=/${ENVIRONMENT}/mlflow
    restart: always

  auto-nlp-minio:
    image: minio/minio
    container_name: ${COMPOSE_PROJECT_NAME}-minio
    command: server /data --console-address ":9001"
    volumes:
      - "/home/autonlp/minio:/data"
    environment:
      MINIO_ROOT_USER: ${AWS_ACCESS_KEY_ID}
      MINIO_ROOT_PASSWORD: ${AWS_SECRET_ACCESS_KEY}
    expose:
      - "9000"
      - "9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - auto-nlp-services
    restart: always

  createbuckets:
    image: minio/mc
    depends_on:
      - auto-nlp-minio
    environment:
      - BUCKET_URI_OR_LOCAL_PATH=$BUCKET_URI_OR_LOCAL_PATH
      - AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID
      - AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY
    entrypoint: >
      /bin/bash -c 'BUCKET_NAME=$$(echo "${BUCKET_URI_OR_LOCAL_PATH}" | sed -n "s/s3:\/\/\(.*\)/\1/p") &&
      echo $$BUCKET_NAME;
      /usr/bin/mc alias set minio http://auto-nlp-minio-${ENVIRONMENT}:9000 ${AWS_ACCESS_KEY_ID} ${AWS_SECRET_ACCESS_KEY};
      /usr/bin/mc rm -r --force minio/$$BUCKET_NAME;
      /usr/bin/mc mb minio/$$BUCKET_NAME;
      exit 0;
      '
    networks:
      - auto-nlp-services
    profiles:
      - setup

networks:
  auto-nlp-deployments:
    name: autonlp-deployments
    driver: 'bridge'
  auto-nlp-services:
    name: ${COMPOSE_PROJECT_NAME}-services

